{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow\n",
    "* Elementos Básicos da Linguagem\n",
    "Fonte: https://mlfromscratch.com/tensorflow-2/#/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf; \n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modo de execução\n",
    "* Eager\n",
    "* Grafo\n",
    "* Código abaixo verifica o modo de execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager execution is enabled (running operations immediately)\n",
      "\n",
      "Turn eager execution off by running: \n",
      "from tensorflow.python.framework.ops import disable_eager_execution\n",
      "disable_eager_execution()\n"
     ]
    }
   ],
   "source": [
    "if(tf.executing_eagerly()):\n",
    "    print('Eager execution is enabled (running operations immediately)\\n')\n",
    "    print(('Turn eager execution off by running: \\n{0}\\n{1}').format('' \\\n",
    "        'from tensorflow.python.framework.ops import disable_eager_execution', \\\n",
    "        'disable_eager_execution()'))\n",
    "else:\n",
    "    print('You are not running eager execution. TensorFlow version >= 2.0.0' \\\n",
    "          'has eager execution enabled by default.')\n",
    "    print(('Turn on eager execution by running: \\n\\n{0}\\n\\nOr upgrade '\\\n",
    "           'your tensorflow version by running:\\n\\n{1}').format(\n",
    "           'tf.compat.v1.enable_eager_execution()',\n",
    "           '!pip install --upgrade tensorflow\\n' \\\n",
    "           '!pip install --upgrade tensorflow-gpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplo de multiplicação de dois valores constante usando tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(15, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(5)\n",
    "b = tf.constant(3)\n",
    "c = a * b\n",
    "print(c)\n",
    "#y_output = tf.session.run(c)\n",
    "#print(y_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Como desligar modo eager\n",
    "* Para retornar ao modo eager, é necessário reiniciar o kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verificar se há GPU disponível para uso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "WARNING:tensorflow:From <ipython-input-4-8db21c955b8a>:4: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "Is your GPU available for use?\n",
      "No, your GPU is NOT available: False\n",
      "\n",
      "Your devices that are available:\n",
      "['/physical_device:CPU:0', '/physical_device:XLA_CPU:0', '/physical_device:XLA_GPU:0']\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "print(('Is your GPU available for use?\\n{0}').format(\n",
    "    'Yes, your GPU is available: True' if tf.test.is_gpu_available() == True else 'No, your GPU is NOT available: False'\n",
    "))\n",
    "\n",
    "print(('\\nYour devices that are available:\\n{0}').format(\n",
    "    [device.name for device in tf.config.experimental.list_physical_devices()]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executando mesmo código em GPU e CPU para comparar tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 0.]\n",
      " [0. 1.]], shape=(2, 2), dtype=float32)\n",
      "0.0020155906677246094\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "/job:localhost/replica:0/task:0/device:GPU:0 unknown device.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f0da1fe629a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Doing operations on CPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Printing how long it took with CPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.6/site-packages/tensorflow_core/python/ops/linalg_ops.py\u001b[0m in \u001b[0;36meye\u001b[0;34m(num_rows, num_columns, batch_shape, dtype, name)\u001b[0m\n\u001b[1;32m    167\u001b[0m                              \u001b[0mbatch_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m                              \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m                              name=name)\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.6/site-packages/tensorflow_core/python/ops/linalg_ops_impl.py\u001b[0m in \u001b[0;36meye\u001b[0;34m(num_rows, num_columns, batch_shape, dtype, name)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_shape\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnum_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mdiag_ones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiag_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_square\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix_diag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiag_ones\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36mones\u001b[0;34m(shape, dtype, name)\u001b[0m\n\u001b[1;32m   2657\u001b[0m         \u001b[0;31m# Create a constant if it won't be very big. Otherwise create a fill op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m         \u001b[0;31m# to prevent serialized GraphDefs from becoming too large.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_constant_if_small\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_constant_if_small\u001b[0;34m(value, shape, dtype, name)\u001b[0m\n\u001b[1;32m   2390\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2391\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2392\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2393\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2394\u001b[0m     \u001b[0;31m# Happens when shape is a Tensor, list with Tensor elements, etc.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    256\u001b[0m   \"\"\"\n\u001b[1;32m    257\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 258\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    264\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: /job:localhost/replica:0/task:0/device:GPU:0 unknown device."
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "cpu_slot = 0\n",
    "gpu_slot = 0\n",
    "\n",
    "# Using CPU at slot 0\n",
    "with tf.device('/CPU:' + str(cpu_slot)):\n",
    "    # Starting a timer\n",
    "    start = time.time()\n",
    "\n",
    "    # Doing operations on CPU\n",
    "    A = tf.constant([[3, 2], [5, 2]])\n",
    "    print(tf.eye(2,2))\n",
    "\n",
    "    # Printing how long it took with CPU\n",
    "    end = time.time() - start\n",
    "    print(end)\n",
    "\n",
    "# Using the GPU at slot 0\n",
    "with tf.device('/GPU:' + str(gpu_slot)):\n",
    "    # Starting a timer\n",
    "    start = time.time()\n",
    "\n",
    "    # Doing operations on CPU\n",
    "    A = tf.constant([[3, 2], [5, 2]])\n",
    "    print(tf.eye(2,2))\n",
    "\n",
    "    # Printing how long it took with CPU\n",
    "    end = time.time() - start\n",
    "    print(end)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operações Comuns com Tensorflow\n",
    "\n",
    "* Montando tensores com tf.constant e tf.Variable\n",
    "* Concatenação de dois tensores com tf.concat\n",
    "* Montando tensores com tf.zeros ou tf.ones\n",
    "* Remodelando  com tf.reshape\n",
    "* Cast de tensores para outros tipos de dados com tf.cast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Montando tensores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a constant tensor A, that does not change\n",
    "A = tf.constant([[3, 2],\n",
    "                 [5, 2]])\n",
    "\n",
    "# Making a Variable tensor VA, which can change. Notice it's .Variable\n",
    "VA = tf.Variable([[3, 2],\n",
    "                 [5, 2]])\n",
    "\n",
    "# Making another tensor B\n",
    "B = tf.constant([[9, 5],\n",
    "                 [1, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding B's columns to A:\n",
      "[[3 2 9 5]\n",
      " [5 2 1 3]]\n",
      "\n",
      "Adding B's rows to A:\n",
      "[[3 2]\n",
      " [5 2]\n",
      " [9 5]\n",
      " [1 3]]\n"
     ]
    }
   ],
   "source": [
    "# Making a constant tensor A, that does not change\n",
    "A = tf.constant([[3, 2],\n",
    "                 [5, 2]])\n",
    "\n",
    "# Making a Variable tensor VA, which can change. Notice it's .Variable\n",
    "VA = tf.Variable([[3, 2],\n",
    "                 [5, 2]])\n",
    "\n",
    "# Making another tensor B\n",
    "B = tf.constant([[9, 5],\n",
    "                 [1, 3]])\n",
    "\n",
    "# Concatenate columns\n",
    "AB_concatenated = tf.concat(values=[A, B], axis=1)\n",
    "print(('Adding B\\'s columns to A:\\n{0}').format(\n",
    "    AB_concatenated.numpy()\n",
    "))\n",
    "\n",
    "# Concatenate rows\n",
    "AB_concatenated = tf.concat(values=[A, B], axis=0)\n",
    "print(('\\nAdding B\\'s rows to A:\\n{0}').format(\n",
    "    AB_concatenated.numpy()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  tf.zeros e tf.ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor full of zeros as int32, 3 rows and 4 columns:\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n",
      "\n",
      "Tensor full of ones as float32, 5 rows and 3 columns:\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Making a tensor filled with zeros. shape=[rows, columns]\n",
    "tensor = tf.zeros(shape=[3, 4], dtype=tf.int32)\n",
    "print(('Tensor full of zeros as int32, 3 rows and 4 columns:\\n{0}').format(\n",
    "    tensor.numpy()\n",
    "))\n",
    "\n",
    "# Making a tensor filled with zeros with data type of float32\n",
    "tensor = tf.ones(shape=[5, 3], dtype=tf.float32)\n",
    "print(('\\nTensor full of ones as float32, 5 rows and 3 columns:\\n{0}').format(\n",
    "    tensor.numpy()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor BEFORE reshape:\n",
      "[[3 2]\n",
      " [5 2]\n",
      " [9 5]\n",
      " [1 3]]\n",
      "\n",
      "Tensor AFTER reshape:\n",
      "[[3 2 5 2 9 5 1 3]]\n"
     ]
    }
   ],
   "source": [
    "# Making a tensor for reshaping\n",
    "tensor = tf.constant([[3, 2],\n",
    "                      [5, 2],\n",
    "                      [9, 5],\n",
    "                      [1, 3]])\n",
    "\n",
    "# Reshaping the tensor into a shape of: shape = [rows, columns]\n",
    "reshaped_tensor = tf.reshape(tensor = tensor,\n",
    "                             shape = [1, 8])\n",
    "\n",
    "print(('Tensor BEFORE reshape:\\n{0}').format(\n",
    "    tensor.numpy()\n",
    "))\n",
    "print(('\\nTensor AFTER reshape:\\n{0}').format(\n",
    "    reshaped_tensor.numpy()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor with floats:\n",
      "[[3.1 2.8]\n",
      " [5.2 2.3]\n",
      " [9.7 5.5]\n",
      " [1.1 3.4]]\n",
      "\n",
      "Tensor cast from float to int (just remove the decimal, no rounding):\n",
      "[[3 2]\n",
      " [5 2]\n",
      " [9 5]\n",
      " [1 3]]\n"
     ]
    }
   ],
   "source": [
    "# Making a tensor\n",
    "tensor = tf.constant([[3.1, 2.8],\n",
    "                      [5.2, 2.3],\n",
    "                      [9.7, 5.5],\n",
    "                      [1.1, 3.4]], \n",
    "                      dtype=tf.float32)\n",
    "\n",
    "tensor_as_int = tf.cast(tensor, tf.int32)\n",
    "\n",
    "print(('Tensor with floats:\\n{0}').format(\n",
    "    tensor.numpy()\n",
    "))\n",
    "print(('\\nTensor cast from float to int (just remove the decimal, no rounding):\\n{0}').format(\n",
    "    tensor_as_int.numpy()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algebra Linear\n",
    "\n",
    "* Transpor o tensor com tf.transpose\n",
    "* Multiplicação de matrizes com tf.matmul\n",
    "* Multiplicação por elementos com tf.multiply\n",
    "* Matriz identidade com tf.eye\n",
    "* Determinante com tf.linalg.det\n",
    "* Produto de ponto com tf.tensordot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The transposed matrix A:\n",
      "[[3 1]\n",
      " [7 9]]\n"
     ]
    }
   ],
   "source": [
    "# Some Matrix A\n",
    "A = tf.constant([[3, 7],\n",
    "                 [1, 9]])\n",
    "\n",
    "A = tf.transpose(A)\n",
    "\n",
    "print(('The transposed matrix A:\\n{0}').format(\n",
    "    A\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MatMul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Multiplication of A and v results in a new Tensor:\n",
      "[[29]\n",
      " [23]]\n"
     ]
    }
   ],
   "source": [
    "# Some Matrix A\n",
    "A = tf.constant([[3, 7],\n",
    "                 [1, 9]])\n",
    "\n",
    "# Some vector v\n",
    "v = tf.constant([[5],\n",
    "                 [2]])\n",
    "\n",
    "# Matrix multiplication of A.v^T\n",
    "Av = tf.matmul(A, v)\n",
    "\n",
    "print(('Matrix Multiplication of A and v results in a new Tensor:\\n{0}').format(\n",
    "    Av\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elemento a elemento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element-wise multiplication of A and v results in a new Tensor:\n",
      "[[15 35]\n",
      " [ 2 18]]\n"
     ]
    }
   ],
   "source": [
    "# Element-wise multiplication\n",
    "Av = tf.multiply(A, v)\n",
    "\n",
    "print(('Element-wise multiplication of A and v results in a new Tensor:\\n{0}').format(\n",
    "    Av\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get rows and columns in tensor A:\n",
      "3 rows\n",
      "2 columns\n",
      "\n",
      "The identity matrix of A:\n",
      "[[1 0]\n",
      " [0 1]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Some Matrix A\n",
    "A = tf.constant([[3, 7],\n",
    "                 [1, 9],\n",
    "                 [2, 5]])\n",
    "\n",
    "# Get number of dimensions\n",
    "rows, columns = A.shape\n",
    "print(('Get rows and columns in tensor A:\\n{0} rows\\n{1} columns').format(\n",
    "    rows, columns\n",
    "))\n",
    "\n",
    "# Making identity matrix\n",
    "A_identity = tf.eye(num_rows = rows,\n",
    "                    num_columns = columns,\n",
    "                    dtype = tf.int32)\n",
    "print(('\\nThe identity matrix of A:\\n{0}').format(\n",
    "    A_identity.numpy()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determinante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The determinant of A:\n",
      "20.0\n"
     ]
    }
   ],
   "source": [
    "# Reusing Matrix A\n",
    "A = tf.constant([[3, 7],\n",
    "                 [1, 9]])\n",
    "\n",
    "# Determinant must be: half, float32, float64, complex64, complex128\n",
    "# Thus, we cast A to the data type float32\n",
    "A = tf.dtypes.cast(A, tf.float32)\n",
    "\n",
    "# Finding the determinant of A\n",
    "det_A = tf.linalg.det(A)\n",
    "\n",
    "print(('The determinant of A:\\n{0}').format(\n",
    "    det_A\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produto Ponto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot product of A.B^T results in a new Tensor:\n",
      "[[8634 2719 8750]\n",
      " [2939 1329 2975]\n",
      " [7573 5341 7545]]\n",
      "\n",
      "Matrix Multiplication of A.B^T results in a new Tensor:\n",
      "[[8634 2719 8750]\n",
      " [2939 1329 2975]\n",
      " [7573 5341 7545]]\n"
     ]
    }
   ],
   "source": [
    "# Defining a 3x3 matrix\n",
    "A = tf.constant([[32, 83, 5],\n",
    "                 [17, 23, 10],\n",
    "                 [75, 39, 52]])\n",
    "\n",
    "# Defining another 3x3 matrix\n",
    "B = tf.constant([[28, 57, 20],\n",
    "                 [91, 10, 95],\n",
    "                 [37, 13, 45]])\n",
    "\n",
    "# Finding the dot product\n",
    "dot_AB = tf.tensordot(a=A, b=B, axes=1).numpy()\n",
    "\n",
    "print(('Dot product of A.B^T results in a new Tensor:\\n{0}').format(\n",
    "    dot_AB\n",
    "))\n",
    "\n",
    "# Which is the same as matrix multiplication in this instance (axes=1)\n",
    "# Matrix multiplication of A and B\n",
    "AB = tf.matmul(A, B)\n",
    "\n",
    "print(('\\nMatrix Multiplication of A.B^T results in a new Tensor:\\n{0}').format(\n",
    "    AB\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradientes\n",
    "## Função de ativação GELU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8673699498176575 is the gradient of GELU with x=0.5\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def gelu(x):\n",
    "    return 0.5*x*(1+tf.tanh(tf.sqrt(2/math.pi)*(x+0.044715*tf.pow(x, 3))))\n",
    "\n",
    "def get_gradient(x, activation_function):\n",
    "    with tf.GradientTape() as gt:\n",
    "        y = activation_function(x)\n",
    "\n",
    "    gradient = gt.gradient(y, x).numpyge\n",
    "\n",
    "    return gradient\n",
    "\n",
    "x = tf.Variable(0.5)\n",
    "gradient = get_gradient(x, gelu)\n",
    "\n",
    "print('{0} is the gradient of GELU with x={1}'.format(\n",
    "    gradient, x.numpy()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without tf.function:  0.07315529487095773\n",
      "With tf.function:  0.06692585907876492\n",
      "The difference:  0.006229435792192817\n",
      "\n",
      "Just imagine when we have to do millions/billions of these calculations, then the difference will be HUGE!\n",
      "Difference times a billion:  6229435.792192817\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "conv_layer = tf.keras.layers.Conv2D(100, 3)\n",
    "\n",
    "@tf.function\n",
    "def conv_fn(image):\n",
    "  return conv_layer(image)\n",
    "\n",
    "image = tf.zeros([1, 200, 200, 100])\n",
    "# warm up\n",
    "conv_layer(image); conv_fn(image)\n",
    "\n",
    "no_tf_fn = timeit.timeit(lambda: conv_layer(image), number=10)\n",
    "with_tf_fn = timeit.timeit(lambda: conv_fn(image), number=10)\n",
    "difference = no_tf_fn - with_tf_fn\n",
    "\n",
    "print(\"Without tf.function: \", no_tf_fn)\n",
    "print(\"With tf.function: \", with_tf_fn)\n",
    "print(\"The difference: \", difference)\n",
    "\n",
    "print(\"\\nJust imagine when we have to do millions/billions of these calculations,\" \\\n",
    "      \" then the difference will be HUGE!\")\n",
    "print(\"Difference times a billion: \", difference*1000000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# custom train and test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "\n",
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load Data & Remove color channels\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Add a channels dimension\n",
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test = x_test[..., tf.newaxis]\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).shuffle(10000).batch(32)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(Model):\n",
    "    def __init__(self,\n",
    "                 loss_object,\n",
    "                 optimizer,\n",
    "                 train_loss,\n",
    "                 train_metric,\n",
    "                 test_loss,\n",
    "                 test_metric):\n",
    "        '''\n",
    "            Setting all the variables for our model.\n",
    "        '''\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1 = Conv2D(32, 3, activation='relu')\n",
    "        self.flatten = Flatten()\n",
    "        self.d1 = Dense(128, activation='relu')\n",
    "        self.d2 = Dense(10, activation='softmax')\n",
    "\n",
    "        self.loss_object = loss_object\n",
    "        self.optimizer = optimizer\n",
    "        self.train_loss = train_loss\n",
    "        self.train_metric = train_metric\n",
    "        self.test_loss = test_loss\n",
    "        self.test_metric = test_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    " def nn_model(self, x):\n",
    "        '''\n",
    "            Defining the architecture of our model. This is where we run \n",
    "            through our whole dataset and return it, when training and \n",
    "            testing.\n",
    "        '''\n",
    "        x = self.conv1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.d1(x)\n",
    "        return self.d2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(self, images, labels):\n",
    "    '''\n",
    "        This is a TensorFlow function, run once for each epoch for the\n",
    "        whole input. We move forward first, then calculate gradients \n",
    "        with Gradient Tape to move backwards.\n",
    "    '''\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = self.nn_model(images)\n",
    "        loss = self.loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, self.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "\n",
    "    self.train_loss(loss)\n",
    "    self.train_metric(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "    @tf.function\n",
    "    def test_step(self, images, labels):\n",
    "        '''\n",
    "            This is a TensorFlow function, run once for each epoch for the\n",
    "            whole input.\n",
    "        '''\n",
    "        predictions = self.nn_model(images)\n",
    "        t_loss = self.loss_object(labels, predictions)\n",
    "\n",
    "        self.test_loss(t_loss)\n",
    "        self.test_metric(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def fit(self, train, test, epochs):\n",
    "        '''\n",
    "            This fit function runs training and testing.\n",
    "        '''\n",
    "        for epoch in range(epochs):\n",
    "            for images, labels in train:\n",
    "                self.train_step(images, labels)\n",
    "\n",
    "            for test_images, test_labels in test:\n",
    "                self.test_step(test_images, test_labels)\n",
    "\n",
    "            template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "            print(template.format(epoch+1,\n",
    "                                  self.train_loss.result(),\n",
    "                                  self.train_metric.result()*100,\n",
    "                                  self.test_loss.result(),\n",
    "                                  self.test_metric.result()*100))\n",
    "\n",
    "            # Reset the metrics for the next epoch\n",
    "            self.train_loss.reset_states()\n",
    "            self.train_metric.reset_states()\n",
    "            self.test_loss.reset_states()\n",
    "            self.test_metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a loss object\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "# Select the optimizer\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# Specify metrics for training\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_metric = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "# Specify metrics for testing\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_metric = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Unrecognized keyword arguments: {'train': <BatchDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float64, tf.uint8)>, 'test': <BatchDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float64, tf.uint8)>}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-9ce3fbc4d8f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m model.fit(train = train_ds,\n\u001b[1;32m     12\u001b[0m           \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m           epochs = EPOCHS)\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    793\u001b[0m       \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nb_epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized keyword arguments: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_compile_was_called\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_call_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Unrecognized keyword arguments: {'train': <BatchDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float64, tf.uint8)>, 'test': <BatchDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float64, tf.uint8)>}"
     ]
    }
   ],
   "source": [
    "# Create an instance of the model\n",
    "model = MyModel(loss_object = loss_object,\n",
    "                optimizer = optimizer,\n",
    "                train_loss = train_loss,\n",
    "                train_metric = train_metric,\n",
    "                test_loss = test_loss,\n",
    "                test_metric = test_metric)\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "model.fit(train = train_ds,\n",
    "          test = test_ds,\n",
    "          epochs = EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
